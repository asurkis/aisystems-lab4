# Лабораторная работа № 4
Выполнил студент группы P33113 Суркис Антон Игоревич<br>
Преподаватель: Болдырева Елена Александровна

## Вариант 15:
- Функция 1 &mdash; `abs(sin(x))`
- Датасет 2 &mdash; рукописные цифры (MNIST)
- Гиперпараметры &mdash; L2-регуляризация, функция активации выходного слоя

<!--
|        | softmax            | relu                | tanh | sigmoid | linear |
|--------|--------------------|---------------------|------|---------|--------|
| -0.1   | 0.7799999713897705 | 0.48500001430511475 | 0.7799999713897705 | 0.8050000071525574 | 0.2199999988079071 |
| 0      | 0.7799999713897705 | 0.2199999988079071 | 0.7799999713897705 | 0.8399999737739563 | 0.2199999988079071 |
| 0.0001 | 0.7799999713897705 | 0.2199999988079071 | 0.8600000143051147 | 0.7799999713897705 | 0.824999988079071 |
| 0.0005 | 0.7799999713897705 | 0.8500000238418579 | 0.2199999988079071 | 0.8500000238418579 | 0.8050000071525574 |
| 0.001  | 0.7799999713897705 | 0.7799999713897705 | 0.8700000047683716 | 0.8500000238418579 | 0.7799999713897705 |
| 0.005  | 0.7799999713897705 | 0.7799999713897705 | 0.8500000238418579 | 0.8500000238418579 | 0.5299999713897705 |
| 0.01   | 0.7799999713897705 | 0.8700000047683716 | 0.2199999988079071 | 0.7799999713897705 | 0.8199999928474426 |
| 0.05   | 0.7799999713897705 | 0.7799999713897705 | 0.7799999713897705 | 0.7799999713897705 | 0.8299999833106995 |
| 0.1    | 0.7799999713897705 | 0.2199999988079071 | 0.2199999988079071 | 0.7799999713897705 | 0.7799999713897705 |
-->
Подбор параметров первой части:
|    *L2* | `softmax` | `relu` | `tanh` | `sigmoid` | `linear` |
|--------:|----------:|-------:|-------:|----------:|---------:|
| -0.1000 |     0.780 |  0.485 |  0.780 |     0.805 |    0.220 |
|  0.0000 |     0.780 |  0.220 |  0.780 |     0.840 |    0.220 |
|  0.0001 |     0.780 |  0.220 |  0.860 |     0.780 |    0.825 |
|  0.0005 |     0.780 |  0.850 |  0.220 |     0.850 |    0.805 |
|  0.0010 |     0.780 |  0.780 |  0.870 |     0.850 |    0.780 |
|  0.0050 |     0.780 |  0.780 |  0.850 |     0.850 |    0.530 |
|  0.0100 |     0.780 |  0.870 |  0.220 |     0.780 |    0.820 |
|  0.0500 |     0.780 |  0.780 |  0.780 |     0.780 |    0.830 |
|  0.1000 |     0.780 |  0.220 |  0.220 |     0.780 |    0.780 |

Лучшие найденные параметры:
- Функция активации &mdash; `relu`
- L2-регуляризация &mdash; 0.01
- Полученная точность &mdash; 87.0%

<!--
|    *L2* | `softmax` | `relu` | `tanh` | `sigmoid` | `linear` |
|--------:|----------:|-------:|-------:|----------:|---------:|
| -0.1000 | 0.11349999904632568 | 0.09799999743700027 | 0.09799999743700027 | 0.18240000307559967 | 0.09809999912977219 |
|  0.0000 | 0.23489999771118164 | 0.09799999743700027 | 0.09799999743700027 | 0.3978999853134155 | 0.0982000008225441 |
|  0.0001 | 0.11349999904632568 | 0.09799999743700027 | 0.09799999743700027 | 0.23160000145435333 | 0.09799999743700027 |
|  0.0005 | 0.11349999904632568 | 0.09799999743700027 | 0.09799999743700027 | 0.6017000079154968 | 0.09799999743700027 |
|  0.0010 | 0.11349999904632568 | 0.10279999673366547 | 0.09799999743700027 | 0.23600000143051147 | 0.12790000438690186 |
|  0.0050 | 0.11349999904632568 | 0.10100000351667404 | 0.09799999743700027 | 0.4959000051021576 | 0.09799999743700027 |
|  0.0100 | 0.11349999904632568 | 0.11349999904632568 | 0.09799999743700027 | 0.833899974822998 | 0.10100000351667404 |
|  0.0500 | 0.11349999904632568 | 0.2556999921798706 | 0.09799999743700027 | 0.8513000011444092 | 0.09799999743700027 |
|  0.1000 | 0.11349999904632568 | 0.038100000470876694 | 0.09799999743700027 | 0.849399983882904 | 0.09799999743700027 |
-->
Подбор параметров второй части:
|    *L2* | `softmax` | `relu` | `tanh` | `sigmoid` | `linear` |
|--------:|----------:|-------:|-------:|----------:|---------:|
| -0.1000 |     0.113 |  0.098 |  0.098 |     0.182 |    0.098 |
|  0.0000 |     0.235 |  0.098 |  0.098 |     0.398 |    0.098 |
|  0.0001 |     0.113 |  0.098 |  0.098 |     0.232 |    0.098 |
|  0.0005 |     0.113 |  0.098 |  0.098 |     0.602 |    0.098 |
|  0.0010 |     0.113 |  0.103 |  0.098 |     0.236 |    0.128 |
|  0.0050 |     0.113 |  0.101 |  0.098 |     0.496 |    0.098 |
|  0.0100 |     0.113 |  0.113 |  0.098 |     0.834 |    0.101 |
|  0.0500 |     0.113 |  0.256 |  0.098 |     0.851 |    0.098 |
|  0.1000 |     0.113 |  0.038 |  0.098 |     0.849 |    0.098 |

Лучшие найденные параметры:
- Функция активации &mdash; `sigmoid`
- L2-регуляризация &mdash; 0.05
- Полученная точность &mdash; 85.1%

При обучении 4 слоями по 20 нейронов в течение 100 эпох точность достигает 93.8% (0.9381999969482422)

## Вывод:
нейросеть &mdash; гибкая модель машинного обучения, с помощью которой можно аппроксимировать
очень многие функции, в том числе те, которые не представляются аналитически, как например
классификация изображений.
